{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object localization\n",
    "One last time, recall our two guiding questions for this week:\n",
    "\n",
    "- _What_ is in an image (e.g. debris, buildings, etc.)?\n",
    "- _Where_ are these things located _in 3D space_ ?\n",
    "\n",
    "Let's take stock of everything we've learned this week. The first two days, we learned about structure from motion. We saw how, so long as you have two images with some overlap, you can reconstruct a scene up to scale in an arbitrary reference frame. If you have some additional information (e.g. GPS location) and can afford to make some additional assumptions (e.g. the ground is flat), you can have a coarse georegistration of every image that is part of the structure from motion sequence. \n",
    "\n",
    "We spent the next two days discussing deep learning. We saw that machine learning can pick up patterns in the data that can aid in the general classification problem. We also saw that, using convolutional neural networks, we were able to extend this approach to the classification of images. \n",
    "\n",
    "Are we done?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## xBD and Image Segmentation\n",
    "*Image segmentation* is a related but distinct problem from image classification. Rather than asking \"is there flooding in the image?\", it asks \"where is there flooding in an image?\". This is a problem that has seen interest in recent years, as it is no longer enough to just say whether there is a human in an image (think self-driving cars). One of the largest image segmentation datasets is called xBD. Here's what a sample pair of images looks like: \n",
    "\n",
    "<img src=\"notebook_images/hurricane-harvey_00000006_post_disaster.png\" width=\"250\"  />\n",
    "\n",
    "<img src=\"notebook_images/targets.png\" width=\"250\"  />\n",
    "\n",
    "Just as the output of our classification CNN was a single label, the output of a segmentation CNN is an entirely new image! \n",
    "In a sense, image segmentation is just pixel-wise classification. This means that image segmentation is a much more challenging task than just image classification. Accordingly, neural networks trained for image segmentation are much more complex than most classification CNN's. The dataset creation is much more complex: absent any other data sources, someone has to literally sit down and click on polygons that contain the target region. For georeferenced satellite imagery this might not be too hard, since you could just overlay OpenStreetMap data on top of the image, but for CAP imagery like ours a single image could take upwards to half an hour. \n",
    "\n",
    "## Class Activation Maps\n",
    "The following approach is adapted from the following paper by Zhou et al: https://arxiv.org/pdf/1512.04150.pdf. It has never been used in a disaster response setting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
